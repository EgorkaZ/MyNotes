# Стохастический градиентный спуск

[[Градиентный спуск]] для бедных

* $w_{0}$ - начальное значение
* $x_1,x_2,\dots,x_{|\mathcal{D}|}$ - некоторый порядок объектов
* $\mu$ - **шаг градиента** или **скорость сходимости**
* $w_{k+1} = w_k - \mu\mathcal{L}(\langle w_k, x_k \rangle y_k)$ 
	* Можем очень сильно упрыгивать от шага к шагу, потому будем проводить балансировку [[Решение задачи линейной классификации#Эмпирический риск]]
* $\mathcal{L}_{k+1} = (1-\alpha)\mathcal{L}_k + \alpha\mathcal{L}(\langle w_k, x_k \rangle y_k)$

Критерий останова: $L$ и/или $w$ почти не меняются

### Пакетный градиентный спуск (mini-batch)

Вместо выдёргивания одного элемента будем брать пачку элементов

Заменим $\mathcal{L}(\langle w_k, x_k \rangle y_k)$ на $\sum_{Kb}^{(K+1)b}\mathcal{L}(\langle w_k, x_k \rangle y_k)$

### Теорема Новикова

Теорема Алекса Новикова говорит, что стохастический градиентный спуск сходится