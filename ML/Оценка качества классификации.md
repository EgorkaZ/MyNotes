# Оценка качества классификации

## Бинарная классификация

### Матрица ошибок

| | Положительный | Отрицательный |
| - | - | - |
| Отнесён к положительным | TP = True Positive | FP = False Positive |
| Отнесён к отрицательным | FN = False Negative | TN = True Negative |

* FP - [[Ошибка первого рода]]
* FN - [[Ошибка второго рода]]
* P = TP + FN - число _положительных_ примеров
* N = TN + FP - число _отрицательных_ примеров

### Определения

#### Recall / sensitivity

(Полнота / чувствительность)
$$ Recall = TPR = \frac{TP}{P} $$

#### Specificity

(Специфичность)
$$ SPC = \frac{TN}{N} $$

#### Precision

(Точность)
$$ Precision = PRV = \frac{TP}{TP + FP} $$

#### Accuracy

Первая примитивная норм статистика
* Будет работать плохо на несбалансированных выборках

(Точность (лол))
$$ Accuracy = ACC = \frac{TP + TN}{P + N} $$

#### F-measure

Классная из-за того, что лежит в \[0, 1\]

$F_\beta$-measure:

$$
F_\beta = (1 + \beta^2) = \frac{Precision \cdot Recall}{\beta^2 \cdot Precision + Recall}
$$

Здесь $\beta$ - мера того, насколько нам важен [[#Precision]]

$F_1$-measure:

$$
F_1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
$$

## На множестве классов

* One vs one классификация
	* Как-нибудь объединяем потом
		* Взвесить
		* Скормить в ансамбль
		* Что-то ещё
* One vs all (one vs rest) классификация
	* Если какой-то один класс у нас важен
* Иерархическая классификация
* Матрица ошибок для многих классов
	* Придётся изобретать новые формулы