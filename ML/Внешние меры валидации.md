# Внешние меры валидации

Идея в оценке обобщающей способности $\mu^A$ ([[Метод обучения|отсюда]]) на *имеющихся* данных

![[Pasted image 20220411225439.png]]

Так сложилось, что у нас скорее всего нет жизненных данных для тестов нашей модели

### Валидация на отложенной выборке

(Hold-out validation, HO)

Разбиваем выборку на две части

$$\mathcal{D} = \mathcal{D}_{train} \cup \mathcal{D}_{test}$$

![[Pasted image 20220411230021.png]]

Будем решать следующую задачу:
$\mu^{val}$ ([[Метод обучения|см.]]), но 
$$
(\mu_A,\mathcal{D}_{train},\mathcal{D}_{test}) = argmin_{\large \mu^A}\mathcal{L}(\mu_A(\mathcal{D}_{train}), \mathcal{D}_{test})
$$

#### Проблема

Здесь мы не обозначили распределение выборки. В задаче об идрисах в этой постановке мы можем сложить в обучающую выборку единственный класс идрисов, и не получить хорошего результата в тестах

### Полная кросс-валидация

Зафиксируем значения $r$ и $e$
$$
|\mathcal{D}_{train}|=r, |\mathcal{D}_{test}|=e
$$

и разобьём $\mathcal{D}$ всеми возможными способами

Будем решать задачу

$$
\mu_{CCV}^{val} (\mathcal{D},r,e) = \frac{1}{C^e_{e+r}}argmin_{\mu^A}\sum_{\large \mathcal{D} = \mathcal{D}_{train}\cup \mathcal{D}_{test}} \mathcal{L}(\mu^A(\mathcal{D}_{train}), \mathcal{D}_{test})
$$

#### Проблемы

Это __очень__, ну просто охренеть, как дорого

### Кросс-валидация

(cross-validation, скользящий контроль)

Разобьём $\mathcal{D}$ на $k$ равных частей. Будем поочерёдно использовать каждую в качестве 
![[Pasted image 20220411234617.png]]

#### K-fold cross validation

Задача:
$$
\mu^{val}_{CV}(\mathcal{D},k) = \frac{1}{k} argmin_{\mu^A}\sum_{i=1}^k \mathcal{L}(\mu^A(\mathcal{D} \backslash \mathcal{D}_i), \mathcal{D}_i)
$$

$k$ обычно 10 (бывает 5, иногда 3)

#### t кросс-валидаций по k блокам

$t \times k$-fold cross-validation

Повторим [[#K-fold cross validation]] t раз

Используется на стохастических методах

#### Кросс-валидация по отдельным объектам

(Leave-one-out cross-validation, LOO)

Как [[#Полная кросс-валидация]], но $e=1$

#### Стратифицированная кросс-валидация

(Stratified k-fold cross-validation)

Набираем блоки так, чтобы каждый класс объектов встречался пропорционально статистике в выборке (обычно просто шафлят)


### О выборе модели после кросс-валидации

Кросс-валидация по 5-ти блокам выдала 5 разных моделей - все плохие, обучаем новые

### Что мы вообще оцениваем

* Не модели, а $\mu^A$
* Для любого набора данных (в разумных пределах) мы должны быть способны построить хорошо обобщённые [[Предсказательная модель|предсказательные модели]]
* Тот метод, который строит лучшие модели в этом смысле, и есть лучший